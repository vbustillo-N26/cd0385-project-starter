{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3e459f",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd005109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U pip\n",
    "# !pip install -U setuptools wheel\n",
    "# !pip install \"numpy<2.0.0\"  # Fix compatibility issue with AutoGluon\n",
    "# !pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "# !pip install autogluon --no-cache-dir\n",
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467b526",
   "metadata": {},
   "source": [
    "### Setup Kaggle API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7dd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# kaggle_dir = os.path.expanduser(\"~/.kaggle\")\n",
    "# !mkdir -p {kaggle_dir}\n",
    "# !touch {kaggle_dir}/kaggle.json\n",
    "# !chmod 600 {kaggle_dir}/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34954a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your user name and key from creating the kaggle account and API token file\n",
    "import json\n",
    "import os\n",
    "kaggle_username = \"vbustillo\"\n",
    "kaggle_key = \"4a62006bdac26949783ce007d3ed2c8e\"\n",
    "\n",
    "# Save API token to the kaggle.json file in the user's home directory\n",
    "kaggle_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "with open(kaggle_path, \"w\") as f:\n",
    "    f.write(json.dumps({\"username\": kaggle_username, \"key\": kaggle_key}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa389de7",
   "metadata": {},
   "source": [
    "### Download and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f316a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset, it will be in a .zip file so you'll need to unzip it as well.\n",
    "# !kaggle competitions download -c bike-sharing-demand\n",
    "# If you already downloaded it you can use the -o command to overwrite the file\n",
    "# !unzip -o bike-sharing-demand.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5c687",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdaf4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1eafef",
   "metadata": {},
   "source": [
    "### Read data and transform it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330302a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hour, day, and month features from datetime\n",
    "# Re-read the data to ensure we have the original features\n",
    "train = pd.read_csv('train.csv', parse_dates=['datetime'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['datetime'])\n",
    "\n",
    "# Remove casual and registered columns from training data\n",
    "train = train.drop(columns=['casual', 'registered'])\n",
    "\n",
    "# Create new time-based features\n",
    "train['hour'] = train['datetime'].dt.hour\n",
    "train['month'] = train['datetime'].dt.month\n",
    "train['dayofweek'] = train['datetime'].dt.dayofweek\n",
    "\n",
    "test['hour'] = test['datetime'].dt.hour\n",
    "test['month'] = test['datetime'].dt.month\n",
    "test['dayofweek'] = test['datetime'].dt.dayofweek\n",
    "\n",
    "train['season'] = train['season'].astype('category')\n",
    "train['weather'] = train['weather'].astype('category')\n",
    "train['hour'] = train['hour'].astype('category')\n",
    "train['month'] = train['month'].astype('category')\n",
    "train['dayofweek'] = train['dayofweek'].astype('category')\n",
    "\n",
    "test['season'] = test['season'].astype('category')\n",
    "test['weather'] = test['weather'].astype('category')\n",
    "test['hour'] = test['hour'].astype('category')\n",
    "test['month'] = test['month'].astype('category')\n",
    "test['dayofweek'] = test['dayofweek'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86428439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use log transformation approach - this is mathematically equivalent to RMSLE\n",
    "# but avoids the metric calculation issues\n",
    "\n",
    "def create_log_transformed_data(train_df):\n",
    "    \"\"\"Transform the target variable to log space\"\"\"\n",
    "    train_log = train_df.copy()\n",
    "    # Add 1 to avoid log(0), then take log\n",
    "    train_log['count'] = np.log1p(train_log['count'])\n",
    "    return train_log\n",
    "\n",
    "def inverse_log_transform(predictions):\n",
    "    \"\"\"Transform predictions back from log space\"\"\"\n",
    "    # Use expm1 which is the inverse of log1p\n",
    "    return np.expm1(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617cf1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features created and log transformation applied!\n",
      "Train shape: (10886, 13)\n",
      "Test shape: (6493, 12)\n",
      "Log-transformed target range: 0.6931 to 6.8855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime season  holiday  workingday weather  temp   atemp  \\\n",
       "0 2011-01-01 00:00:00      1        0           0       1  9.84  14.395   \n",
       "1 2011-01-01 01:00:00      1        0           0       1  9.02  13.635   \n",
       "2 2011-01-01 02:00:00      1        0           0       1  9.02  13.635   \n",
       "3 2011-01-01 03:00:00      1        0           0       1  9.84  14.395   \n",
       "4 2011-01-01 04:00:00      1        0           0       1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed     count hour month dayofweek  \n",
       "0        81        0.0  2.833213    0     1         5  \n",
       "1        80        0.0  3.713572    1     1         5  \n",
       "2        80        0.0  3.496508    2     1         5  \n",
       "3        75        0.0  2.639057    3     1         5  \n",
       "4        75        0.0  0.693147    4     1         5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply log transformation to the target variable\n",
    "train_log = create_log_transformed_data(train)\n",
    "\n",
    "print(\"New features created and log transformation applied!\")\n",
    "print(f\"Train shape: {train_log.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Log-transformed target range: {train_log['count'].min():.4f} to {train_log['count'].max():.4f}\")\n",
    "train_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f933538",
   "metadata": {},
   "source": [
    "## Step 6: Hyper parameter optimization\n",
    "* There are many options for hyper parameter optimization.\n",
    "* Options are to change the AutoGluon higher level parameters or the individual model hyperparameters.\n",
    "* The hyperparameters of the models themselves that are in AutoGluon. Those need the `hyperparameter` and `hyperparameter_tune_kwargs` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca57bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Thu Apr 24 20:29:18 PDT 2025; root:xnu-10063.141.1.705.2~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.20 GB / 16.00 GB (32.5%)\n",
      "Disk Space Avail:   185.54 GB / 460.43 GB (40.3%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 450s of the 1800s of remaining time (25%).\n",
      "2025-07-26 17:16:42,338\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-07-26 17:16:43,595\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/project/autogluon_models/bike_sharing_clean_nb_01/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/utils.py:97: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   import pkg_resources\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Beginning AutoGluon training ... Time limit = 448s\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m AutoGluon will save models to \"/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/project/autogluon_models/bike_sharing_clean_nb_01/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Train Data Rows:    9676\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Train Data Columns: 12\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Label Column:       count\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tAvailable Memory:                    5142.69 MB\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('category', []) : 5 | ['season', 'weather', 'hour', 'month', 'dayofweek']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('datetime', []) : 1 | ['datetime']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('int', [])      : 3 | ['holiday', 'workingday', 'humidity']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('category', [])             : 5 | ['season', 'weather', 'hour', 'month', 'dayofweek']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('int', [])                  : 1 | ['humidity']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t12 features in original data used to generate 16 features in processed data.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.73 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t'GBM': [{}],\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t'XGB': [{}],\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t'CAT': [{'iterations': 1000, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 3, 'bagging_temperature': 1, 'random_strength': 1, 'verbose': 0}, {'iterations': 2000, 'learning_rate': 0.01, 'depth': 6, 'l2_leaf_reg': 5, 'bagging_temperature': 1.5, 'random_strength': 1.5, 'verbose': 0}],\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t'NN_TORCH': [{'num_layers': 2, 'dropout_prob': 0.1, 'hidden_size': 64}, {'num_layers': 3, 'dropout_prob': 0.2, 'hidden_size': 128}, {'num_layers': 4, 'dropout_prob': 0.3, 'hidden_size': 256}],\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t'RF': [{'n_estimators': 100, 'max_depth': 15, 'max_features': 0.8}, {'n_estimators': 200, 'max_depth': 20, 'max_features': 0.9}],\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t'XT': [{'n_estimators': 100, 'max_depth': 15}, {'n_estimators': 200, 'max_depth': 20}],\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 298.39s of the 447.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=30074)\u001b[0m [1000]\tvalid_set's rmse: 0.258184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.273\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t1.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.62s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: RandomForest_BAG_L1 ... Training model for up to 293.02s of the 442.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2981\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: RandomForest_2_BAG_L1 ... Training model for up to 292.34s of the 441.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2945\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t1.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 290.99s of the 440.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.52%)\n",
      "\u001b[36m(_ray_fit pid=30096)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/try_import.py:69: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(_ray_fit pid=30096)\u001b[0m   from pkg_resources import parse_version  # pylint: disable=import-outside-toplevel\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2965\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t10.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: CatBoost_2_BAG_L1 ... Training model for up to 278.59s of the 427.90s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.92%)\n",
      "\u001b[36m(_ray_fit pid=30095)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/try_import.py:69: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=30095)\u001b[0m   from pkg_resources import parse_version  # pylint: disable=import-outside-toplevel\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.3287\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t18.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 257.74s of the 407.05s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=30125)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/try_import.py:69: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=30125)\u001b[0m   from pkg_resources import parse_version  # pylint: disable=import-outside-toplevel\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2944\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: ExtraTrees_2_BAG_L1 ... Training model for up to 257.36s of the 406.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2895\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 256.54s of the 405.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2943\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t3.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 250.95s of the 400.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=30141)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/try_import.py:107: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=30141)\u001b[0m   from pkg_resources import parse_version  # pylint: disable=import-outside-toplevel\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2903\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t67.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: NeuralNetTorch_2_BAG_L1 ... Training model for up to 181.34s of the 330.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2944\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t45.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: NeuralNetTorch_3_BAG_L1 ... Training model for up to 134.09s of the 283.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2901\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t86.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 194.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.455, 'RandomForest_2_BAG_L1': 0.136, 'NeuralNetTorch_BAG_L1': 0.136, 'NeuralNetTorch_3_BAG_L1': 0.136, 'CatBoost_BAG_L1': 0.045, 'ExtraTrees_2_BAG_L1': 0.045, 'NeuralNetTorch_2_BAG_L1': 0.045}\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.264\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 194.34s of the 194.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.28%)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2689\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: RandomForest_BAG_L2 ... Training model for up to 191.32s of the 191.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2702\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t1.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: RandomForest_2_BAG_L2 ... Training model for up to 189.60s of the 189.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2694\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t3.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 185.77s of the 185.77s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.66%)\n",
      "\u001b[36m(_ray_fit pid=30253)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/try_import.py:69: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(_ray_fit pid=30253)\u001b[0m   from pkg_resources import parse_version  # pylint: disable=import-outside-toplevel\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2665\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t9.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: CatBoost_2_BAG_L2 ... Training model for up to 174.64s of the 174.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.00%)\n",
      "\u001b[36m(_ray_fit pid=30248)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/try_import.py:69: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=30248)\u001b[0m   from pkg_resources import parse_version  # pylint: disable=import-outside-toplevel\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2659\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t21.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: ExtraTrees_BAG_L2 ... Training model for up to 150.96s of the 150.95s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=30270)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/try_import.py:69: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=30270)\u001b[0m   from pkg_resources import parse_version  # pylint: disable=import-outside-toplevel\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.268\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: ExtraTrees_2_BAG_L2 ... Training model for up to 150.48s of the 150.48s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2665\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.19s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 149.36s of the 149.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2684\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t1.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 145.60s of the 145.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_ray_fit pid=30282)\u001b[0m /Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/try_import.py:107: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=30282)\u001b[0m   from pkg_resources import parse_version  # pylint: disable=import-outside-toplevel\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2739\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t11.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: NeuralNetTorch_2_BAG_L2 ... Training model for up to 131.74s of the 131.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2773\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t9.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: NeuralNetTorch_3_BAG_L2 ... Training model for up to 120.05s of the 120.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.2832\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t13.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 104.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.238, 'ExtraTrees_2_BAG_L2': 0.238, 'CatBoost_BAG_L2': 0.19, 'CatBoost_2_BAG_L2': 0.19, 'RandomForest_2_BAG_L2': 0.048, 'XGBoost_BAG_L2': 0.048, 'NeuralNetTorch_BAG_L2': 0.048}\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t-0.263\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m AutoGluon training complete, total runtime = 342.89s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 778.0 rows/s (1210 batch size)\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/project/autogluon_models/bike_sharing_clean_nb_01/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=30062)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         ExtraTrees_BAG_L2      -0.255119  -0.268000  root_mean_squared_error        1.421784       1.881476  236.792862                 0.042851                0.082228           0.357795            2       True         18\n",
      "1       WeightedEnsemble_L3      -0.255736  -0.262979  root_mean_squared_error        1.865883       2.338432  285.335078                 0.001605                0.000458           0.026780            3       True         24\n",
      "2       ExtraTrees_2_BAG_L2      -0.255840  -0.266474  root_mean_squared_error        1.489615       1.985277  237.299366                 0.110683                0.186029           0.864299            2       True         19\n",
      "3           CatBoost_BAG_L2      -0.256864  -0.266537  root_mean_squared_error        1.402340       1.824459  245.644145                 0.023407                0.025211           9.209078            2       True         16\n",
      "4           LightGBM_BAG_L2      -0.257111  -0.268913  root_mean_squared_error        1.416819       1.852484  237.272806                 0.037886                0.053236           0.837739            2       True         13\n",
      "5       WeightedEnsemble_L2      -0.257266  -0.263959  root_mean_squared_error        1.044000       1.224466  213.574016                 0.001702                0.000389           0.014369            2       True         12\n",
      "6            XGBoost_BAG_L2      -0.258030  -0.268409  root_mean_squared_error        1.469401       1.852319  238.259786                 0.090468                0.053071           1.824718            2       True         20\n",
      "7         CatBoost_2_BAG_L2      -0.258211  -0.265858  root_mean_squared_error        1.413052       1.833782  258.126016                 0.034119                0.034534          21.690948            2       True         17\n",
      "8     RandomForest_2_BAG_L2      -0.259291  -0.269378  root_mean_squared_error        1.467899       1.983315  240.003829                 0.088966                0.184067           3.568762            2       True         15\n",
      "9       RandomForest_BAG_L2      -0.260267  -0.270206  root_mean_squared_error        1.420103       1.879182  238.046940                 0.041170                0.079934           1.611873            2       True         14\n",
      "10    NeuralNetTorch_BAG_L2      -0.263858  -0.273946  root_mean_squared_error        1.516636       1.855062  248.150492                 0.137703                0.055814          11.715425            2       True         21\n",
      "11          LightGBM_BAG_L1      -0.265950  -0.273036  root_mean_squared_error        0.353983       0.619372    1.826073                 0.353983                0.619372           1.826073            1       True          1\n",
      "12  NeuralNetTorch_2_BAG_L2      -0.265970  -0.277290  root_mean_squared_error        1.472975       1.859643  245.993759                 0.094042                0.060395           9.558692            2       True         22\n",
      "13    NeuralNetTorch_BAG_L1      -0.266599  -0.290275  root_mean_squared_error        0.063936       0.048239   67.678680                 0.063936                0.048239          67.678680            1       True          9\n",
      "14  NeuralNetTorch_3_BAG_L1      -0.269469  -0.290114  root_mean_squared_error        0.100186       0.082633   86.855225                 0.100186                0.082633          86.855225            1       True         11\n",
      "15  NeuralNetTorch_2_BAG_L1      -0.269665  -0.294404  root_mean_squared_error        0.085544       0.054257   45.121465                 0.085544                0.054257          45.121465            1       True         10\n",
      "16  NeuralNetTorch_3_BAG_L2      -0.271072  -0.283156  root_mean_squared_error        1.469851       1.876156  249.439546                 0.090918                0.076908          13.004478            2       True         23\n",
      "17           XGBoost_BAG_L1      -0.278239  -0.294316  root_mean_squared_error        0.205667       0.350715    3.360578                 0.205667                0.350715           3.360578            1       True          8\n",
      "18      ExtraTrees_2_BAG_L1      -0.279405  -0.289460  root_mean_squared_error        0.097646       0.180796    0.560751                 0.097646                0.180796           0.560751            1       True          7\n",
      "19        ExtraTrees_BAG_L1      -0.280616  -0.294380  root_mean_squared_error        0.049465       0.088353    0.256478                 0.049465                0.088353           0.256478            1       True          6\n",
      "20    RandomForest_2_BAG_L1      -0.281531  -0.294505  root_mean_squared_error        0.100175       0.174001    1.117333                 0.100175                0.174001           1.117333            1       True          3\n",
      "21      RandomForest_BAG_L1      -0.282790  -0.298103  root_mean_squared_error        0.040872       0.081387    0.576481                 0.040872                0.081387           0.576481            1       True          2\n",
      "22          CatBoost_BAG_L1      -0.287150  -0.296457  root_mean_squared_error        0.240828       0.064778   10.400119                 0.240828                0.064778          10.400119            1       True          4\n",
      "23        CatBoost_2_BAG_L1      -0.317327  -0.328728  root_mean_squared_error        0.040631       0.054717   18.681883                 0.040631                0.054717          18.681883            1       True          5\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t349s\t = DyStack   runtime |\t1451s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/autogluon/common/utils/utils.py:97: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Beginning AutoGluon training ... Time limit = 1451s\n",
      "AutoGluon will save models to \"/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/project/autogluon_models/bike_sharing_clean_nb_01\"\n",
      "Train Data Rows:    10886\n",
      "Train Data Columns: 12\n",
      "Label Column:       count\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5234.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.63 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 5 | ['season', 'weather', 'hour', 'month', 'dayofweek']\n",
      "\t\t('datetime', []) : 1 | ['datetime']\n",
      "\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])      : 3 | ['holiday', 'workingday', 'humidity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             : 5 | ['season', 'weather', 'hour', 'month', 'dayofweek']\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 1 | ['humidity']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t12 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'CAT': [{'iterations': 1000, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 3, 'bagging_temperature': 1, 'random_strength': 1, 'verbose': 0}, {'iterations': 2000, 'learning_rate': 0.01, 'depth': 6, 'l2_leaf_reg': 5, 'bagging_temperature': 1.5, 'random_strength': 1.5, 'verbose': 0}],\n",
      "\t'NN_TORCH': [{'num_layers': 2, 'dropout_prob': 0.1, 'hidden_size': 64}, {'num_layers': 3, 'dropout_prob': 0.2, 'hidden_size': 128}, {'num_layers': 4, 'dropout_prob': 0.3, 'hidden_size': 256}],\n",
      "\t'RF': [{'n_estimators': 100, 'max_depth': 15, 'max_features': 0.8}, {'n_estimators': 200, 'max_depth': 20, 'max_features': 0.9}],\n",
      "\t'XT': [{'n_estimators': 100, 'max_depth': 15}, {'n_estimators': 200, 'max_depth': 20}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 966.93s of the 1450.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t-0.2711\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 962.26s of the 1446.09s of remaining time.\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.2928\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L1 ... Training model for up to 961.55s of the 1445.38s of remaining time.\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.2894\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 959.99s of the 1443.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.42%)\n",
      "\t-0.2973\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.68s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_2_BAG_L1 ... Training model for up to 947.31s of the 1431.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.52%)\n",
      "\t-0.339\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.96s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 924.17s of the 1407.99s of remaining time.\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.292\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_2_BAG_L1 ... Training model for up to 923.72s of the 1407.54s of remaining time.\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.2871\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 922.80s of the 1406.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
      "\t-0.2896\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.55s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 917.22s of the 1401.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t-0.2891\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.77s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_2_BAG_L1 ... Training model for up to 854.44s of the 1338.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t-0.2892\t = Validation score   (-root_mean_squared_error)\n",
      "\t52.28s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_3_BAG_L1 ... Training model for up to 799.96s of the 1283.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t-0.2845\t = Validation score   (-root_mean_squared_error)\n",
      "\t162.59s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1119.09s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.429, 'NeuralNetTorch_3_BAG_L1': 0.238, 'RandomForest_2_BAG_L1': 0.19, 'CatBoost_BAG_L1': 0.048, 'NeuralNetTorch_BAG_L1': 0.048, 'NeuralNetTorch_2_BAG_L1': 0.048}\n",
      "\t-0.2615\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1119.05s of the 1119.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\t-0.2667\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 1115.77s of the 1115.76s of remaining time.\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.2668\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.89s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L2 ... Training model for up to 1113.75s of the 1113.74s of remaining time.\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.2665\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.73s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1109.70s of the 1109.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.63%)\n",
      "\t-0.2628\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.81s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_2_BAG_L2 ... Training model for up to 1094.94s of the 1094.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.79%)\n",
      "\t-0.2627\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.25s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L2 ... Training model for up to 1066.68s of the 1066.67s of remaining time.\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.2653\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_2_BAG_L2 ... Training model for up to 1066.09s of the 1066.09s of remaining time.\n",
      "/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/venv39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.2634\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1064.74s of the 1064.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\t-0.2686\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1060.72s of the 1060.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.8s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_2_BAG_L2 ... Training model for up to 1045.66s of the 1045.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t-0.2736\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.56s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_3_BAG_L2 ... Training model for up to 1032.05s of the 1032.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t-0.2824\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.44s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 1012.48s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.261, 'LightGBM_BAG_L1': 0.217, 'ExtraTrees_2_BAG_L2': 0.174, 'NeuralNetTorch_3_BAG_L1': 0.13, 'RandomForest_BAG_L2': 0.087, 'CatBoost_2_BAG_L2': 0.087, 'RandomForest_2_BAG_L1': 0.043}\n",
      "\t-0.2597\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 438.37s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 982.4 rows/s (1361 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/victorbustillo/Documents/D01 GitHub/cd0385-project-starter/project/autogluon_models/bike_sharing_clean_nb_01\")\n"
     ]
    }
   ],
   "source": [
    "predictor_new_hpo = TabularPredictor(\n",
    "    label=\"count\",\n",
    "    eval_metric=\"root_mean_squared_error\",\n",
    "    path='autogluon_models/bike_sharing_clean_nb_01'\n",
    ").fit(\n",
    "    train_data=train_log, \n",
    "    time_limit=1800, \n",
    "    presets='best_quality',\n",
    "    # Simple hyperparameter configuration - just specify different models to include\n",
    "    hyperparameters={\n",
    "        'GBM': {},  # Use default LightGBM with AutoGluon's automatic tuning\n",
    "        'XGB': {},  # Use default XGBoost with AutoGluon's automatic tuning\n",
    "        'CAT': [\n",
    "            {\n",
    "                'iterations': 1000,\n",
    "                'learning_rate': 0.05,\n",
    "                'depth': 6,\n",
    "                'l2_leaf_reg': 3,\n",
    "                'bagging_temperature': 1,\n",
    "                'random_strength': 1,\n",
    "                'verbose': 0\n",
    "            },\n",
    "            {\n",
    "                'iterations': 2000,\n",
    "                'learning_rate': 0.01,\n",
    "                'depth': 6,\n",
    "                'l2_leaf_reg': 5,\n",
    "                'bagging_temperature': 1.5,\n",
    "                'random_strength': 1.5,\n",
    "                'verbose': 0\n",
    "            }\n",
    "        ],  # Use CatBoost\n",
    "        'NN_TORCH': [    # Neural Network with different configurations\n",
    "            {'num_layers': 2, 'dropout_prob': 0.1, 'hidden_size': 64},\n",
    "            {'num_layers': 3, 'dropout_prob': 0.2, 'hidden_size': 128},\n",
    "            {'num_layers': 4, 'dropout_prob': 0.3, 'hidden_size': 256}\n",
    "\n",
    "        ],\n",
    "        'RF': [    # Random Forest with different configurations\n",
    "            {'n_estimators': 100, 'max_depth': 15, 'max_features': 0.8},\n",
    "            {'n_estimators': 200, 'max_depth': 20, 'max_features': 0.9},\n",
    "        ],\n",
    "        'XT': [    # Extra Trees with different configurations\n",
    "            {'n_estimators': 100, 'max_depth': 15},\n",
    "            {'n_estimators': 200, 'max_depth': 20},\n",
    "        ]\n",
    "    },\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8333c071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions range: 1.68 to 883.51\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the new feature model\n",
    "predictions_log_clean_nb = predictor_new_hpo.predict(test, as_pandas=True)\n",
    "\n",
    "# Transform predictions back from log space\n",
    "predictions_clean_nb = inverse_log_transform(predictions_log_clean_nb)\n",
    "\n",
    "print(f\"Predictions range: {predictions_clean_nb.min():.2f} to {predictions_clean_nb    .max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b01e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val              eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L3  -0.259709  root_mean_squared_error       2.087677  357.117467                0.001058           0.022272            3       True         24\n",
      "1       WeightedEnsemble_L2  -0.261492  root_mean_squared_error       0.995273  289.132828                0.000293           0.028136            2       True         12\n",
      "2         CatBoost_2_BAG_L2  -0.262659  root_mean_squared_error       1.766087  341.358137                0.066022          26.253704            2       True         17\n",
      "3           CatBoost_BAG_L2  -0.262757  root_mean_squared_error       1.735993  327.917949                0.035928          12.813516            2       True         16\n",
      "4       ExtraTrees_2_BAG_L2  -0.263449  root_mean_squared_error       1.900553  316.141609                0.200489           1.037176            2       True         19\n",
      "5         ExtraTrees_BAG_L2  -0.265268  root_mean_squared_error       1.787712  315.546208                0.087648           0.441775            2       True         18\n",
      "6     RandomForest_2_BAG_L2  -0.266474  root_mean_squared_error       1.897522  318.837388                0.197458           3.732955            2       True         15\n",
      "7           LightGBM_BAG_L2  -0.266732  root_mean_squared_error       1.759926  316.047945                0.059862           0.943512            2       True         13\n",
      "8       RandomForest_BAG_L2  -0.266757  root_mean_squared_error       1.784178  316.990799                0.084114           1.886366            2       True         14\n",
      "9            XGBoost_BAG_L2  -0.268594  root_mean_squared_error       1.747443  317.105663                0.047379           2.001230            2       True         20\n",
      "10    NeuralNetTorch_BAG_L2  -0.270027  root_mean_squared_error       1.755646  327.908218                0.055581          12.803785            2       True         21\n",
      "11          LightGBM_BAG_L1  -0.271092  root_mean_squared_error       0.565911    1.515698                0.565911           1.515698            1       True          1\n",
      "12  NeuralNetTorch_2_BAG_L2  -0.273615  root_mean_squared_error       1.778601  326.668164                0.078536          11.563731            2       True         22\n",
      "13  NeuralNetTorch_3_BAG_L2  -0.282374  root_mean_squared_error       1.773605  332.543568                0.073541          17.439135            2       True         23\n",
      "14  NeuralNetTorch_3_BAG_L1  -0.284457  root_mean_squared_error       0.089401  162.585632                0.089401         162.585632            1       True         11\n",
      "15      ExtraTrees_2_BAG_L1  -0.287140  root_mean_squared_error       0.179511    0.614353                0.179511           0.614353            1       True          7\n",
      "16    NeuralNetTorch_BAG_L1  -0.289116  root_mean_squared_error       0.048927   60.771463                0.048927          60.771463            1       True          9\n",
      "17  NeuralNetTorch_2_BAG_L1  -0.289224  root_mean_squared_error       0.057053   52.277691                0.057053          52.277691            1       True         10\n",
      "18    RandomForest_2_BAG_L1  -0.289444  root_mean_squared_error       0.175615    1.275502                0.175615           1.275502            1       True          3\n",
      "19           XGBoost_BAG_L1  -0.289647  root_mean_squared_error       0.299307    3.551518                0.299307           3.551518            1       True          8\n",
      "20        ExtraTrees_BAG_L1  -0.292038  root_mean_squared_error       0.082299    0.300281                0.082299           0.300281            1       True          6\n",
      "21      RandomForest_BAG_L1  -0.292776  root_mean_squared_error       0.079613    0.577993                0.079613           0.577993            1       True          2\n",
      "22          CatBoost_BAG_L1  -0.297302  root_mean_squared_error       0.058073   10.678706                0.058073          10.678706            1       True          4\n",
      "23        CatBoost_2_BAG_L1  -0.339033  root_mean_squared_error       0.064354   20.955596                0.064354          20.955596            1       True          5\n",
      "Number of models trained: 24\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])             : 5 | ['season', 'weather', 'hour', 'month', 'dayofweek']\n",
      "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "('int', [])                  : 1 | ['humidity']\n",
      "('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForest_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'RandomForest_2_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_2_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTrees_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'ExtraTrees_2_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetTorch_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetTorch_2_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetTorch_3_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForest_BAG_L2': 'StackerEnsembleModel_RF',\n",
       "  'RandomForest_2_BAG_L2': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_2_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTrees_BAG_L2': 'StackerEnsembleModel_XT',\n",
       "  'ExtraTrees_2_BAG_L2': 'StackerEnsembleModel_XT',\n",
       "  'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetTorch_BAG_L2': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetTorch_2_BAG_L2': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetTorch_3_BAG_L2': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBM_BAG_L1': np.float64(-0.2710921039557529),\n",
       "  'RandomForest_BAG_L1': np.float64(-0.2927762497434452),\n",
       "  'RandomForest_2_BAG_L1': np.float64(-0.2894443200909354),\n",
       "  'CatBoost_BAG_L1': np.float64(-0.2973021634369926),\n",
       "  'CatBoost_2_BAG_L1': np.float64(-0.3390328514153999),\n",
       "  'ExtraTrees_BAG_L1': np.float64(-0.2920383391917998),\n",
       "  'ExtraTrees_2_BAG_L1': np.float64(-0.28713987682878456),\n",
       "  'XGBoost_BAG_L1': np.float64(-0.2896468053763435),\n",
       "  'NeuralNetTorch_BAG_L1': np.float64(-0.2891156870968506),\n",
       "  'NeuralNetTorch_2_BAG_L1': np.float64(-0.2892241847754655),\n",
       "  'NeuralNetTorch_3_BAG_L1': np.float64(-0.28445732888776004),\n",
       "  'WeightedEnsemble_L2': np.float64(-0.26149184157435973),\n",
       "  'LightGBM_BAG_L2': np.float64(-0.2667324037314893),\n",
       "  'RandomForest_BAG_L2': np.float64(-0.26675744791277356),\n",
       "  'RandomForest_2_BAG_L2': np.float64(-0.26647366879053425),\n",
       "  'CatBoost_BAG_L2': np.float64(-0.2627567722116644),\n",
       "  'CatBoost_2_BAG_L2': np.float64(-0.26265859298364463),\n",
       "  'ExtraTrees_BAG_L2': np.float64(-0.26526798698757),\n",
       "  'ExtraTrees_2_BAG_L2': np.float64(-0.26344919869601796),\n",
       "  'XGBoost_BAG_L2': np.float64(-0.2685935201226002),\n",
       "  'NeuralNetTorch_BAG_L2': np.float64(-0.27002674498358825),\n",
       "  'NeuralNetTorch_2_BAG_L2': np.float64(-0.2736149494621031),\n",
       "  'NeuralNetTorch_3_BAG_L2': np.float64(-0.2823737867999983),\n",
       "  'WeightedEnsemble_L3': np.float64(-0.2597090170045143)},\n",
       " 'model_best': 'WeightedEnsemble_L3',\n",
       " 'model_paths': {'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'RandomForest_BAG_L1': ['RandomForest_BAG_L1'],\n",
       "  'RandomForest_2_BAG_L1': ['RandomForest_2_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'CatBoost_2_BAG_L1': ['CatBoost_2_BAG_L1'],\n",
       "  'ExtraTrees_BAG_L1': ['ExtraTrees_BAG_L1'],\n",
       "  'ExtraTrees_2_BAG_L1': ['ExtraTrees_2_BAG_L1'],\n",
       "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
       "  'NeuralNetTorch_BAG_L1': ['NeuralNetTorch_BAG_L1'],\n",
       "  'NeuralNetTorch_2_BAG_L1': ['NeuralNetTorch_2_BAG_L1'],\n",
       "  'NeuralNetTorch_3_BAG_L1': ['NeuralNetTorch_3_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'LightGBM_BAG_L2': ['LightGBM_BAG_L2'],\n",
       "  'RandomForest_BAG_L2': ['RandomForest_BAG_L2'],\n",
       "  'RandomForest_2_BAG_L2': ['RandomForest_2_BAG_L2'],\n",
       "  'CatBoost_BAG_L2': ['CatBoost_BAG_L2'],\n",
       "  'CatBoost_2_BAG_L2': ['CatBoost_2_BAG_L2'],\n",
       "  'ExtraTrees_BAG_L2': ['ExtraTrees_BAG_L2'],\n",
       "  'ExtraTrees_2_BAG_L2': ['ExtraTrees_2_BAG_L2'],\n",
       "  'XGBoost_BAG_L2': ['XGBoost_BAG_L2'],\n",
       "  'NeuralNetTorch_BAG_L2': ['NeuralNetTorch_BAG_L2'],\n",
       "  'NeuralNetTorch_2_BAG_L2': ['NeuralNetTorch_2_BAG_L2'],\n",
       "  'NeuralNetTorch_3_BAG_L2': ['NeuralNetTorch_3_BAG_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3']},\n",
       " 'model_fit_times': {'LightGBM_BAG_L1': 1.5156981945037842,\n",
       "  'RandomForest_BAG_L1': 0.5779929161071777,\n",
       "  'RandomForest_2_BAG_L1': 1.2755019664764404,\n",
       "  'CatBoost_BAG_L1': 10.678705930709839,\n",
       "  'CatBoost_2_BAG_L1': 20.95559597015381,\n",
       "  'ExtraTrees_BAG_L1': 0.3002808094024658,\n",
       "  'ExtraTrees_2_BAG_L1': 0.6143531799316406,\n",
       "  'XGBoost_BAG_L1': 3.551518201828003,\n",
       "  'NeuralNetTorch_BAG_L1': 60.77146315574646,\n",
       "  'NeuralNetTorch_2_BAG_L1': 52.27769088745117,\n",
       "  'NeuralNetTorch_3_BAG_L1': 162.5856318473816,\n",
       "  'WeightedEnsemble_L2': 0.028136014938354492,\n",
       "  'LightGBM_BAG_L2': 0.943511962890625,\n",
       "  'RandomForest_BAG_L2': 1.8863661289215088,\n",
       "  'RandomForest_2_BAG_L2': 3.73295521736145,\n",
       "  'CatBoost_BAG_L2': 12.81351613998413,\n",
       "  'CatBoost_2_BAG_L2': 26.253704071044922,\n",
       "  'ExtraTrees_BAG_L2': 0.441774845123291,\n",
       "  'ExtraTrees_2_BAG_L2': 1.0371758937835693,\n",
       "  'XGBoost_BAG_L2': 2.001230001449585,\n",
       "  'NeuralNetTorch_BAG_L2': 12.803784847259521,\n",
       "  'NeuralNetTorch_2_BAG_L2': 11.56373119354248,\n",
       "  'NeuralNetTorch_3_BAG_L2': 17.4391348361969,\n",
       "  'WeightedEnsemble_L3': 0.022272109985351562},\n",
       " 'model_pred_times': {'LightGBM_BAG_L1': 0.5659112930297852,\n",
       "  'RandomForest_BAG_L1': 0.07961320877075195,\n",
       "  'RandomForest_2_BAG_L1': 0.1756150722503662,\n",
       "  'CatBoost_BAG_L1': 0.058072566986083984,\n",
       "  'CatBoost_2_BAG_L1': 0.06435441970825195,\n",
       "  'ExtraTrees_BAG_L1': 0.08229875564575195,\n",
       "  'ExtraTrees_2_BAG_L1': 0.17951107025146484,\n",
       "  'XGBoost_BAG_L1': 0.29930710792541504,\n",
       "  'NeuralNetTorch_BAG_L1': 0.04892683029174805,\n",
       "  'NeuralNetTorch_2_BAG_L1': 0.057053327560424805,\n",
       "  'NeuralNetTorch_3_BAG_L1': 0.0894007682800293,\n",
       "  'WeightedEnsemble_L2': 0.00029277801513671875,\n",
       "  'LightGBM_BAG_L2': 0.05986189842224121,\n",
       "  'RandomForest_BAG_L2': 0.08411407470703125,\n",
       "  'RandomForest_2_BAG_L2': 0.19745802879333496,\n",
       "  'CatBoost_BAG_L2': 0.03592848777770996,\n",
       "  'CatBoost_2_BAG_L2': 0.06602239608764648,\n",
       "  'ExtraTrees_BAG_L2': 0.08764791488647461,\n",
       "  'ExtraTrees_2_BAG_L2': 0.20048904418945312,\n",
       "  'XGBoost_BAG_L2': 0.0473787784576416,\n",
       "  'NeuralNetTorch_BAG_L2': 0.05558133125305176,\n",
       "  'NeuralNetTorch_2_BAG_L2': 0.0785362720489502,\n",
       "  'NeuralNetTorch_3_BAG_L2': 0.07354068756103516,\n",
       "  'WeightedEnsemble_L3': 0.0010581016540527344},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'model_hyperparams': {'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'RandomForest_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForest_2_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'CatBoost_2_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'ExtraTrees_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTrees_2_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'NeuralNetTorch_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'NeuralNetTorch_2_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'NeuralNetTorch_3_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'RandomForest_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForest_2_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'CatBoost_2_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'ExtraTrees_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTrees_2_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'XGBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'NeuralNetTorch_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'NeuralNetTorch_2_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'NeuralNetTorch_3_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None}},\n",
       " 'leaderboard':                       model  score_val              eval_metric  \\\n",
       " 0       WeightedEnsemble_L3  -0.259709  root_mean_squared_error   \n",
       " 1       WeightedEnsemble_L2  -0.261492  root_mean_squared_error   \n",
       " 2         CatBoost_2_BAG_L2  -0.262659  root_mean_squared_error   \n",
       " 3           CatBoost_BAG_L2  -0.262757  root_mean_squared_error   \n",
       " 4       ExtraTrees_2_BAG_L2  -0.263449  root_mean_squared_error   \n",
       " 5         ExtraTrees_BAG_L2  -0.265268  root_mean_squared_error   \n",
       " 6     RandomForest_2_BAG_L2  -0.266474  root_mean_squared_error   \n",
       " 7           LightGBM_BAG_L2  -0.266732  root_mean_squared_error   \n",
       " 8       RandomForest_BAG_L2  -0.266757  root_mean_squared_error   \n",
       " 9            XGBoost_BAG_L2  -0.268594  root_mean_squared_error   \n",
       " 10    NeuralNetTorch_BAG_L2  -0.270027  root_mean_squared_error   \n",
       " 11          LightGBM_BAG_L1  -0.271092  root_mean_squared_error   \n",
       " 12  NeuralNetTorch_2_BAG_L2  -0.273615  root_mean_squared_error   \n",
       " 13  NeuralNetTorch_3_BAG_L2  -0.282374  root_mean_squared_error   \n",
       " 14  NeuralNetTorch_3_BAG_L1  -0.284457  root_mean_squared_error   \n",
       " 15      ExtraTrees_2_BAG_L1  -0.287140  root_mean_squared_error   \n",
       " 16    NeuralNetTorch_BAG_L1  -0.289116  root_mean_squared_error   \n",
       " 17  NeuralNetTorch_2_BAG_L1  -0.289224  root_mean_squared_error   \n",
       " 18    RandomForest_2_BAG_L1  -0.289444  root_mean_squared_error   \n",
       " 19           XGBoost_BAG_L1  -0.289647  root_mean_squared_error   \n",
       " 20        ExtraTrees_BAG_L1  -0.292038  root_mean_squared_error   \n",
       " 21      RandomForest_BAG_L1  -0.292776  root_mean_squared_error   \n",
       " 22          CatBoost_BAG_L1  -0.297302  root_mean_squared_error   \n",
       " 23        CatBoost_2_BAG_L1  -0.339033  root_mean_squared_error   \n",
       " \n",
       "     pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       " 0        2.087677  357.117467                0.001058           0.022272   \n",
       " 1        0.995273  289.132828                0.000293           0.028136   \n",
       " 2        1.766087  341.358137                0.066022          26.253704   \n",
       " 3        1.735993  327.917949                0.035928          12.813516   \n",
       " 4        1.900553  316.141609                0.200489           1.037176   \n",
       " 5        1.787712  315.546208                0.087648           0.441775   \n",
       " 6        1.897522  318.837388                0.197458           3.732955   \n",
       " 7        1.759926  316.047945                0.059862           0.943512   \n",
       " 8        1.784178  316.990799                0.084114           1.886366   \n",
       " 9        1.747443  317.105663                0.047379           2.001230   \n",
       " 10       1.755646  327.908218                0.055581          12.803785   \n",
       " 11       0.565911    1.515698                0.565911           1.515698   \n",
       " 12       1.778601  326.668164                0.078536          11.563731   \n",
       " 13       1.773605  332.543568                0.073541          17.439135   \n",
       " 14       0.089401  162.585632                0.089401         162.585632   \n",
       " 15       0.179511    0.614353                0.179511           0.614353   \n",
       " 16       0.048927   60.771463                0.048927          60.771463   \n",
       " 17       0.057053   52.277691                0.057053          52.277691   \n",
       " 18       0.175615    1.275502                0.175615           1.275502   \n",
       " 19       0.299307    3.551518                0.299307           3.551518   \n",
       " 20       0.082299    0.300281                0.082299           0.300281   \n",
       " 21       0.079613    0.577993                0.079613           0.577993   \n",
       " 22       0.058073   10.678706                0.058073          10.678706   \n",
       " 23       0.064354   20.955596                0.064354          20.955596   \n",
       " \n",
       "     stack_level  can_infer  fit_order  \n",
       " 0             3       True         24  \n",
       " 1             2       True         12  \n",
       " 2             2       True         17  \n",
       " 3             2       True         16  \n",
       " 4             2       True         19  \n",
       " 5             2       True         18  \n",
       " 6             2       True         15  \n",
       " 7             2       True         13  \n",
       " 8             2       True         14  \n",
       " 9             2       True         20  \n",
       " 10            2       True         21  \n",
       " 11            1       True          1  \n",
       " 12            2       True         22  \n",
       " 13            2       True         23  \n",
       " 14            1       True         11  \n",
       " 15            1       True          7  \n",
       " 16            1       True          9  \n",
       " 17            1       True         10  \n",
       " 18            1       True          3  \n",
       " 19            1       True          8  \n",
       " 20            1       True          6  \n",
       " 21            1       True          2  \n",
       " 22            1       True          4  \n",
       " 23            1       True          5  }"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_new_hpo.fit_summary(verbosity=1, show_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54123dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe for new features model\n",
    "submission_clean_nb = pd.read_csv('sampleSubmission.csv')\n",
    "submission_clean_nb[\"count\"] = predictions_clean_nb\n",
    "submission_clean_nb.to_csv(\"submission_clean_nb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f0a9d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 188k/188k [00:03<00:00, 55.7kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission_clean_nb.csv -m \"clean notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd8867bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName                        date                        description                                status                     publicScore  privateScore  \n",
      "------------------------------  --------------------------  -----------------------------------------  -------------------------  -----------  ------------  \n",
      "submission_clean_nb.csv         2025-07-26 20:53:13         clean notebook                             SubmissionStatus.COMPLETE  0.41055      0.41055       \n",
      "submission_new_hpo.csv          2025-07-26 15:07:49         hyperparameter optimization submission     SubmissionStatus.COMPLETE  0.41055      0.41055       \n",
      "submission_new_features.csv     2025-07-26 14:49:28         new features local                         SubmissionStatus.COMPLETE  1.03018      1.03018       \n",
      "submission_new_hpo.csv          2025-07-26 13:57:44.233000  new features with hyperparameters          SubmissionStatus.COMPLETE  0.47026      0.47026       \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
